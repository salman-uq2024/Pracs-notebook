{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salman-uq2024/Pracs-notebook/blob/main/PracW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Sn5zSNyN6UCv",
        "outputId": "0702fae7-f2ba-4fd5-bf22-c620624eb684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Mount google colab to drive to access to the dataset (uncomment if you use Google Colab + Drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7_HQqqP608G"
      },
      "source": [
        "# Q1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GdrCuq6_6z9_"
      },
      "outputs": [],
      "source": [
        "# TODO: Load dataset\n",
        "w3classif = pd.read_csv('/content/drive/My Drive/Colab Notebooks//w3classif.csv', header=None).to_numpy()\n",
        "# print(\"Loaded dataset shape:\", w3classif.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GHGgsCKw7OQL",
        "outputId": "8122786a-f8e7-4d2f-f6ef-f8c4d9863cf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of splits created: 10\n"
          ]
        }
      ],
      "source": [
        "def create_train_test_data(data, test_size=0.3):\n",
        "    \"\"\"\n",
        "    Create 10 different shuffled train/test set pairs from the given dataset.\n",
        "\n",
        "    Parameters:\n",
        "        data (numpy.ndarray): The dataset to be split.\n",
        "        test_size (float): Proportion of the dataset to include in the test split.\n",
        "\n",
        "    Returns:\n",
        "        trains (list): List of training sets.\n",
        "        tests (list): List of test sets.\n",
        "    \"\"\"\n",
        "    trains, tests = [], []\n",
        "\n",
        "    for i in range(10):\n",
        "        # train_test_split shuffles data by default.\n",
        "        # Use a different random_state for each iteration to get different splits.\n",
        "        train_data, test_data = train_test_split(data, test_size=test_size, random_state=i, shuffle=True)\n",
        "        trains.append(train_data)\n",
        "        tests.append(test_data)\n",
        "\n",
        "    return trains, tests\n",
        "\n",
        "# Create the 10 different train/test splits\n",
        "trains, tests = create_train_test_data(w3classif, test_size=0.3)\n",
        "print(\"Number of splits created:\", len(trains))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFcjavtQ8Zp7"
      },
      "source": [
        "# Q2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "C-xKodm78eHS"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "def repeat_knn(trials=10, test_size=0.3):\n",
        "    \"\"\"\n",
        "    Repeat k-NN classification for multiple trials using different train/test splits.\n",
        "\n",
        "    Parameters:\n",
        "        trials (int): Number of trials (should be 10).\n",
        "        test_size (float): Proportion of the dataset to use as the test split.\n",
        "\n",
        "    Returns:\n",
        "        train_losses (list): List of training losses (misclassification rates) for each trial.\n",
        "        test_losses (list): List of test losses (misclassification rates) for each trial.\n",
        "    \"\"\"\n",
        "    # For storing losses\n",
        "    train_losses, test_losses = [], []\n",
        "\n",
        "    # Create train and test datasets (using the function defined in W5 Q1)\n",
        "    trains, tests = create_train_test_data(w3classif, test_size=test_size)\n",
        "\n",
        "    for i in range(trials):\n",
        "        # Get the i-th train/test split\n",
        "        train_data = trains[i]\n",
        "        test_data = tests[i]\n",
        "\n",
        "        # Split train data into features and target\n",
        "        # Assuming the target (class label) is the last column and features are the preceding columns.\n",
        "        X_train = train_data[:, :-1]\n",
        "        y_train = train_data[:, -1]\n",
        "\n",
        "        # Split test data into features and target\n",
        "        X_test = test_data[:, :-1]\n",
        "        y_test = test_data[:, -1]\n",
        "\n",
        "        # Initialize the k-NN classifier (using k=3)\n",
        "        knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "        # Train the classifier on the training data\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions on the training and test data\n",
        "        y_train_pred = knn.predict(X_train)\n",
        "        y_test_pred = knn.predict(X_test)\n",
        "\n",
        "        # Calculate training and test accuracy\n",
        "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "        # Calculate training and test loss (misclassification rate)\n",
        "        train_loss = 1 - train_accuracy\n",
        "        test_loss = 1 - test_accuracy\n",
        "\n",
        "        # Store losses\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "    return train_losses, test_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NqW6b8EY-NMr",
        "outputId": "1e140720-a621-4a98-96fa-2075a5bd353a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg Training Loss (Misclassification Rate): 2.46%\n",
            "Avg Test Loss (Misclassification Rate): 4.58%\n"
          ]
        }
      ],
      "source": [
        "# Print the average training and test losses for 10 trials using the function implemented above\n",
        "train_losses, test_losses = repeat_knn(trials=10, test_size=0.3)\n",
        "print(f'Avg Training Loss (Misclassification Rate): {np.array(train_losses).mean() * 100:.2f}%')\n",
        "print(f'Avg Test Loss (Misclassification Rate): {np.array(test_losses).mean() * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, test_losses = repeat_knn(trials=10, test_size=0.3)\n",
        "avg_train_loss_70 = np.mean(train_losses)\n",
        "avg_test_loss_70 = np.mean(test_losses)\n",
        "std_train_70 = np.std(train_losses, ddof=1)\n",
        "std_test_70 = np.std(test_losses, ddof=1)\n",
        "print(\"70/30 Split\")\n",
        "print(\"Avg Training Loss: {:.3f}\".format(avg_train_loss_70))\n",
        "print(\"Avg Test Loss: {:.3f}\".format(avg_test_loss_70))\n",
        "print(\"Std Dev Training Loss: {:.3f}\".format(std_train_70))\n",
        "print(\"Std Dev Test Loss: {:.3f}\".format(std_test_70))"
      ],
      "metadata": {
        "id": "Z2vmEwxfUzFP",
        "outputId": "0e4e8ea9-0145-448a-af13-9371ce4aa55f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/30 Split\n",
            "Avg Training Loss: 0.025\n",
            "Avg Test Loss: 0.046\n",
            "Std Dev Training Loss: 0.007\n",
            "Std Dev Test Loss: 0.016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p4axUHW-mYY"
      },
      "source": [
        "# Q3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "et4o2flU-YdO",
        "outputId": "05a6ba33-3e11-4173-d3b5-758b67d2ae4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Size: 0.5\n",
            "Average Training Loss: 0.029\n",
            "Average Test Loss: 0.046\n",
            "----------------------------------------\n",
            "Test Set Size: 0.1\n",
            "Average Training Loss: 0.027\n",
            "Average Test Loss: 0.048\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# TODO: Define all possible test set sizes\n",
        "test_sizes = [0.5, 0.1]\n",
        "\n",
        "# Loop over each test set size, repeat the experiments, and print average losses\n",
        "for ts in test_sizes:\n",
        "    # Get the train/test losses using our previously defined function repeat_knn\n",
        "    train_losses, test_losses = repeat_knn(trials=10, test_size=ts)\n",
        "\n",
        "    print(\"Test Set Size: {}\".format(ts))\n",
        "    print(\"Average Training Loss: {:.3f}\".format(np.mean(train_losses)))\n",
        "    print(\"Average Test Loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sizes = [0.5, 0.1]  # 50/50 and 90/10 splits\n",
        "for ts in test_sizes:\n",
        "    train_losses, test_losses = repeat_knn(trials=10, test_size=ts)\n",
        "    avg_train_loss = np.mean(train_losses)\n",
        "    avg_test_loss = np.mean(test_losses)\n",
        "    print(f\"Split for test_size={ts}\")\n",
        "    print(\"Avg Training Loss: {:.3f}\".format(avg_train_loss))\n",
        "    print(\"Avg Test Loss: {:.3f}\".format(avg_test_loss))\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "iWTnq1TbU5Ma",
        "outputId": "2ca850a9-1040-44c0-a6bc-3275fe2c016c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split for test_size=0.5\n",
            "Avg Training Loss: 0.029\n",
            "Avg Test Loss: 0.046\n",
            "----------------------------------------\n",
            "Split for test_size=0.1\n",
            "Avg Training Loss: 0.027\n",
            "Avg Test Loss: 0.048\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xClMuw8A_BWF"
      },
      "source": [
        "# Q4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bj_HNZyV_KTE",
        "outputId": "369ec784-c277-46ad-de7e-7941dba25663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set size: 0.3\n",
            "Standard Deviation of Training Losses: 0.007\n",
            "Standard Deviation of Test Losses: 0.016\n",
            "----------------------------------------\n",
            "Test set size: 0.5\n",
            "Standard Deviation of Training Losses: 0.010\n",
            "Standard Deviation of Test Losses: 0.008\n",
            "----------------------------------------\n",
            "Test set size: 0.1\n",
            "Standard Deviation of Training Losses: 0.005\n",
            "Standard Deviation of Test Losses: 0.043\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# TODO: Define all possible test set sizes\n",
        "test_sizes = [0.3, 0.5, 0.1]\n",
        "\n",
        "for ts in test_sizes:\n",
        "    # Get the train and test losses over 10 trials for the given test size.\n",
        "    train_losses, test_losses = repeat_knn(trials=10, test_size=ts)\n",
        "\n",
        "    # Calculate sample standard deviation for both training and test losses.\n",
        "    std_train = np.std(train_losses, ddof=1)\n",
        "    std_test = np.std(test_losses, ddof=1)\n",
        "\n",
        "    print(f\"Test set size: {ts}\")\n",
        "    print(f\"Standard Deviation of Training Losses: {std_train:.3f}\")\n",
        "    print(f\"Standard Deviation of Test Losses: {std_test:.3f}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sizes = [0.3, 0.5, 0.1]  # 70/30, 50/50, 90/10 splits\n",
        "for ts in test_sizes:\n",
        "    train_losses, test_losses = repeat_knn(trials=10, test_size=ts)\n",
        "    std_train = np.std(train_losses, ddof=1)\n",
        "    std_test = np.std(test_losses, ddof=1)\n",
        "    print(f\"Test set size: {ts}\")\n",
        "    print(\"Std Dev Training Loss: {:.3f}\".format(std_train))\n",
        "    print(\"Std Dev Test Loss: {:.3f}\".format(std_test))\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "YWNmn1SWU98j",
        "outputId": "6bdb6198-cb17-4d32-e66e-8cdd9e375403",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set size: 0.3\n",
            "Std Dev Training Loss: 0.007\n",
            "Std Dev Test Loss: 0.016\n",
            "----------------------------------------\n",
            "Test set size: 0.5\n",
            "Std Dev Training Loss: 0.010\n",
            "Std Dev Test Loss: 0.008\n",
            "----------------------------------------\n",
            "Test set size: 0.1\n",
            "Std Dev Training Loss: 0.005\n",
            "Std Dev Test Loss: 0.043\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrYcoSg__jdY"
      },
      "source": [
        "# Q5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bNkpYItl_Oh5",
        "outputId": "a24287eb-0aa9-4ef7-f393-2a4652f6ddbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10-Fold Cross Validation:\n",
            "Mean Error: 0.050\n",
            "Standard Deviation of Error: 0.049\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(42)\n",
        "w3classif_shuffled = w3classif[np.random.permutation(w3classif.shape[0])]\n",
        "\n",
        "# Split the dataset into features and target\n",
        "# Assuming the target is in the last column and the features are all preceding columns.\n",
        "X = w3classif_shuffled[:, :-1]\n",
        "y = w3classif_shuffled[:, -1]\n",
        "\n",
        "# Initialize the k-NN classifier (using k=3)\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 10\n",
        "\n",
        "# Perform cross-validation; scoring returns accuracy scores by default.\n",
        "cv_scores = cross_val_score(knn, X, y, cv=num_folds, scoring='accuracy')\n",
        "\n",
        "# Convert accuracies to errors (misclassification rate)\n",
        "cv_errors = 1 - cv_scores\n",
        "\n",
        "# Calculate mean and sample standard deviation (ddof=1 for sample std)\n",
        "mean_error = np.mean(cv_errors)\n",
        "std_error = np.std(cv_errors, ddof=1)\n",
        "\n",
        "# Print the results\n",
        "print(\"10-Fold Cross Validation:\")\n",
        "print(\"Mean Error: {:.3f}\".format(mean_error))\n",
        "print(\"Standard Deviation of Error: {:.3f}\".format(std_error))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "np.random.seed(42)\n",
        "w3classif_shuffled = w3classif[np.random.permutation(w3classif.shape[0])]\n",
        "X = w3classif_shuffled[:, :-1]\n",
        "y = w3classif_shuffled[:, -1]\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "num_folds = 10\n",
        "cv_scores = cross_val_score(knn, X, y, cv=num_folds, scoring='accuracy')\n",
        "cv_errors = 1 - cv_scores\n",
        "mean_cv_error = np.mean(cv_errors)\n",
        "std_cv_error = np.std(cv_errors, ddof=1)\n",
        "print(\"10-Fold Cross Validation\")\n",
        "print(\"Mean Error: {:.3f}\".format(mean_cv_error))\n",
        "print(\"Std Dev of Error: {:.3f}\".format(std_cv_error))"
      ],
      "metadata": {
        "id": "1Hqyc4PAVhiN",
        "outputId": "289275b2-873e-42ad-f0e2-618e7ea33eae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10-Fold Cross Validation\n",
            "Mean Error: 0.050\n",
            "Std Dev of Error: 0.049\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}